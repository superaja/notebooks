{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13f.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YEy-jyemdq00hWabag1dPRHnKIRB28Aq",
      "authorship_tag": "ABX9TyMJJ43ClcE7+WxnVVCoN5Jw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "723760ac658c48fba003d3a2d56b86d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4f487002a0334626a1f46b06c5199511",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab62c10d357e4d91867c7c34d9bf898f",
              "IPY_MODEL_d161b5c0cc834abfaf82241ada82e87d"
            ]
          }
        },
        "4f487002a0334626a1f46b06c5199511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab62c10d357e4d91867c7c34d9bf898f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f253b949eb1a400c9944a1d359f89f9e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70a4e807b98b4d05b8e35b87d5c37aba"
          }
        },
        "d161b5c0cc834abfaf82241ada82e87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3068b6ec9ea34991b853f543e21d0acf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87/87 [00:38&lt;00:00,  2.27it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcab2407b23046269670fd4912b8a48c"
          }
        },
        "f253b949eb1a400c9944a1d359f89f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70a4e807b98b4d05b8e35b87d5c37aba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3068b6ec9ea34991b853f543e21d0acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcab2407b23046269670fd4912b8a48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "222633e10ddc4e6fa0a4b8c43d8d54e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53e1d3908b2c4428bdef328aeafe9888",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_832b881ad5d3449e8579448f22f70566",
              "IPY_MODEL_e48dc694c3a2458abb2b9d7739228362"
            ]
          }
        },
        "53e1d3908b2c4428bdef328aeafe9888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "832b881ad5d3449e8579448f22f70566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5426d7f81f5442e826b87034ec4f5f8",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_468c6f25445e49b28f0e2fc31f44a2a7"
          }
        },
        "e48dc694c3a2458abb2b9d7739228362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ea0319fc075470cb33e7e5bde490806",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1624/1624 [20:33&lt;00:00,  1.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d674cbc01424bd0ae50eac1b675080f"
          }
        },
        "f5426d7f81f5442e826b87034ec4f5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "468c6f25445e49b28f0e2fc31f44a2a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ea0319fc075470cb33e7e5bde490806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d674cbc01424bd0ae50eac1b675080f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/superaja/notebooks/blob/master/13f.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llZChhqKdcx_"
      },
      "source": [
        "# Quarterly 13F\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import uuid\n",
        "import datetime\n",
        "from os import path\n",
        "import os\n",
        "import json\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from pymongo import MongoClient\n",
        "import uuid\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "db = get_mongo_client()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp3e7bIqTbpt",
        "outputId": "b7a0255b-674a-4c15-d74c-7607a5db3c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# Load Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sGkRQcabWf-"
      },
      "source": [
        "# load gsheet auth\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXe03PGsGzRZ"
      },
      "source": [
        "# helper functions\n",
        "def accession_number_parser(an):\n",
        "  split_list = an.split(\"-\")\n",
        "  sub_url1 = split_list[0].lstrip(\"0\")\n",
        "  sub_url2 = str(split_list[0]+ split_list[1] + split_list[2])\n",
        "  return sub_url1, sub_url2\n",
        "\n",
        "def check_empty(file):\n",
        "  path_data = '/content/drive/My Drive/Analytics/13fdata/Q420data/'\n",
        "  df = pd.read_csv(path_data+file)\n",
        "  r, c = df.shape\n",
        "  if r == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "def accession_number_check(an):\n",
        "  path_downloaded = '/content/drive/My Drive/Analytics/13fdata/'\n",
        "  download_status_df = pd.read_csv(path_downloaded+\"download_status.csv\")\n",
        "  acc_number = list(download_status_df['Accession Number'].unique())\n",
        "  if str(an) in acc_number:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "def reset_rank():\n",
        "  # reset rank in meta file\n",
        "  rank_reset_df = pd.read_csv('/content/drive/My Drive/Analytics/13fdata/download_status.csv')\n",
        "  rank_reset_df['Qrank'] = rank_reset_df.groupby('Filer')['Time'].rank(ascending=True, method=\"first\")\n",
        "  if path.exists('/content/drive/My Drive/Analytics/13fdata/' + \"download_status.csv\"):\n",
        "    rank_reset_df.to_csv('/content/drive/My Drive/Analytics/13fdata/' + \"download_status.csv\", mode='a', header=False, index=False)\n",
        "  else: \n",
        "    rank_reset_df.to_csv('/content/drive/My Drive/Analytics/13fdata/' + \"download_status.csv\", index=False)\n",
        "\n",
        "#cusip lookup\n",
        "def cusip_lookup(cusip):\n",
        "  symList = []\n",
        "  #path_to_lkp = '/content/drive/My Drive/Analytics/13fdata/CUSIP_LKP.csv'\n",
        "  newCUSIP = []\n",
        "  url = \"https://quotes.fidelity.com/mmnet/SymLookup.phtml?reqforlookup=REQUESTFORLOOKUP&productid=mmnet&isLoggedIn=mmnet&rows=50&for=stock&by=cusip&criteria=\"+cusip+\"&submit=Search\"\n",
        "  resp = requests.get(url=url)\n",
        "  soup = BeautifulSoup(resp.content, 'html.parser' )\n",
        "  #print (soup.find_all('font', {\"class\": \"smallfont\"})[0].text)\n",
        "  sym_list = soup.find_all('a')\n",
        "  for s in sym_list:\n",
        "    x = re.search(\"QUOTE_TYPE\", s.get(\"href\"))\n",
        "    if x:\n",
        "      symList.append(s.text)\n",
        "    else:\n",
        "      pass\n",
        "  if len(symList) > 0:\n",
        "    cusip_mdb(cusip, symList[0], \"\")\n",
        "    '''\n",
        "    newCUSIP.append({\n",
        "        \"SYMBOL\": symList[0],\n",
        "        \"CUSIP\": str(cusip)\n",
        "    })\n",
        "    cusip_df = pd.DataFrame(newCUSIP, columns=[\"SYMBOL\", \"CUSIP\"]) # Replace\n",
        "    cusip_df.to_csv(path_to_lkp, mode='a', header=False, index=False) # Replace\n",
        "    #return symList[0]\n",
        "    '''\n",
        "  else:\n",
        "    cusip_mdb(cusip, \"Not Found\", \"\")\n",
        "    '''\n",
        "    newCUSIP.append({\n",
        "        \"SYMBOL\": \"Not Found\",\n",
        "        \"CUSIP\": str(cusip)\n",
        "    })\n",
        "    cusip_df = pd.DataFrame(newCUSIP, columns=[\"SYMBOL\", \"CUSIP\"]) # Replace\n",
        "    print (cusip_df)\n",
        "    cusip_df.to_csv(path_to_lkp, mode='a', header=False, index=False) # Replace\n",
        "    #return \"Not Found\"\n",
        "    '''\n",
        "\n",
        "# Function to remove errored filers\n",
        "\n",
        "def ignoredFilers():\n",
        "  meta_df = pd.read_csv('/content/drive/My Drive/Analytics/13fdata/download_status.csv')\n",
        "  filers = list(meta_df[meta_df[\"Process Status\"].isin([\"DQ Check\", \"Error in QoQ\", \"Empty File\"])][\"Filer\"].unique())\n",
        "  meta_df.loc[meta_df[\"Filer\"].isin(filers),\"Process Status\"] = \"Not Included\" # Updates bad filers\n",
        "  print(\"Total Filers Ignored: \", len(filers))\n",
        "  meta_df.to_csv('/content/drive/My Drive/Analytics/13fdata/download_status.csv', index=False)\n",
        "\n",
        "\n",
        "def dqCheck(files):\n",
        "  # check empty files = non=parallel\n",
        "  try:\n",
        "    all_df = []\n",
        "    for f in tqdm(files):\n",
        "      fileCheck = check_empty(f)\n",
        "      if fileCheck != 1:\n",
        "        #print(f, \" is Empty\")\n",
        "        all_df.append(f)\n",
        "      else: \n",
        "        pass\n",
        "    return all_df\n",
        "  except Exception as e:\n",
        "    se = str(e)\n",
        "    return se\n",
        "\n",
        "def dqCheckP(f):\n",
        "  # check empty files = Parallel\n",
        "  try:\n",
        "    fileCheck = check_empty(f)\n",
        "    if fileCheck != 1:\n",
        "      print(f, \" is Empty\")\n",
        "      return f\n",
        "    else: \n",
        "      pass\n",
        "  except Exception as e:\n",
        "    se = str(e)\n",
        "    return se\n",
        "\n",
        "# size\n",
        "\n",
        "def fileSize(f):\n",
        "  b = os.path.getsize(\"/content/drive/My Drive/Analytics/13fdata/Q420data/\"+f)\n",
        "  return b/1e3\n",
        "\n",
        "# mongo helper\n",
        "mongo_path = 'mongodb://osadmin:Subzero!4@ds145304.mlab.com:45304/os?retryWrites=false'\n",
        "\n",
        "def get_mongo_client():\n",
        "  client = MongoClient(mongo_path)\n",
        "  return client.os"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sJDr5MV9plD"
      },
      "source": [
        "# Works but not used\n",
        "def cusipLkp(cusip):\n",
        "  cusipType = ['stock', 'index', 'fund']\n",
        "  symbol = []\n",
        "  base_url = \"https://quotes.fidelity.com/mmnet/SymLookup.phtml?reqforlookup=REQUESTFORLOOKUP&productid=mmnet&isLoggedIn=mmnet&rows=50&for=\"\n",
        "  for ct in cusipType:\n",
        "    symList = []\n",
        "    url = base_url + ct + \"&by=cusip&criteria=\"+cusip+\"&submit=Search\"\n",
        "    resp = requests.get(url=url)\n",
        "    soup = BeautifulSoup(resp.content, 'html.parser' )\n",
        "    sym_list = soup.find_all('a')\n",
        "    for s in sym_list:\n",
        "      x = re.search(\"QUOTE_TYPE\", s.get(\"href\"))\n",
        "      if x:\n",
        "        symList.append(s.text)\n",
        "    \n",
        "    if len(symList) > 0:\n",
        "      symbol.append(symList[0])\n",
        "\n",
        "  if len(symbol) > 0:\n",
        "    pass\n",
        "  else:\n",
        "    symbol = [\"Not Available\"]\n",
        "\n",
        "  return symbol[0]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HVDrELIL_T_"
      },
      "source": [
        "# Data Extraction\n",
        "\n",
        "'''\n",
        "1. Identify empty / wrong infoTable - log it as empty table in meta file\n",
        "2. Dynamically change Quarter Location for downloaded files\n",
        "3. Archive older files\n",
        "4. Log meta into a database and not file\n",
        "5. \n",
        "'''\n",
        "\n",
        "def get13FData(cik_dict, q):\n",
        "  db = get_mongo_client()\n",
        "  folder = q+\"data\"\n",
        "\n",
        "  f = open('/content/drive/My Drive/Analytics/13fdata/log.txt', 'a+')\n",
        "\n",
        "  # define end point\n",
        "  endpoint = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
        "\n",
        "  for cik, name in cik_dict.items():\n",
        "    print (\"Extracting for \" + name)\n",
        "    param_dict = {\"action\": \"getcompany\",\n",
        "                  \"CIK\": cik,\n",
        "                  \"type\":\"13F\",\n",
        "                  \"dateb\": \"\",\n",
        "                  \"owner\": \"\",\n",
        "                  \"include\": \"\",\n",
        "                  \"count\": \"8\", # last 2 years\n",
        "                  \"output\": \"atom\"}\n",
        "    response = requests.get(url=endpoint, params = param_dict)\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "    entries = soup.find_all('entry')\n",
        "\n",
        "    base_url = \"https://www.sec.gov/Archives/edgar/data/\" # for info_table\n",
        "\n",
        "    \n",
        "\n",
        "    for entry in entries:\n",
        "      try:\n",
        "        download_data = []\n",
        "        accession_number = entry.find('accession-number').text\n",
        "        #print(accession_number)\n",
        "        check_an = accession_number_check_mdb(accession_number) # check if file already downloaded\n",
        "        if check_an == 1:\n",
        "          print(accession_number, check_an)\n",
        "          sub_url1, sub_url2 = accession_number_parser(str(accession_number))\n",
        "          final_url = base_url+ sub_url1 + '/' + sub_url2 + '/' + accession_number + '-index.htm'\n",
        "          r = requests.get(final_url)\n",
        "          print(r.status_code)\n",
        "          # Parse\n",
        "          s = BeautifulSoup(r.content, 'html.parser')\n",
        "          links = s.find_all('a')\n",
        "          sub = \".xml\"\n",
        "          for l in links:\n",
        "            if sub in l.text and \"primary\" not in l.text:\n",
        "              info_table_xml = 'https://www.sec.gov'+l.get('href')\n",
        "              print(l.text, info_table_xml)\n",
        "              log_str = l.text + \", \" + info_table_xml\n",
        "              f.write(log_str)\n",
        "          \n",
        "          # filing metadata\n",
        "          event = s.findAll(\"div\", {\"class\":\"infoHead\"})\n",
        "          date = s.findAll(\"div\", {\"class\": \"info\"})\n",
        "          final_event = [e.text for e in event]\n",
        "          final_date = [d.text for d in date]\n",
        "          file_meta = dict(zip(final_event, final_date))\n",
        "\n",
        "        \n",
        "          # extract the info table\n",
        "          if info_table_xml:\n",
        "            resp = requests.get(info_table_xml)\n",
        "            soup = BeautifulSoup(resp.content, 'xml')\n",
        "            row = soup.find_all('infoTable')\n",
        "            \n",
        "            each_row = []\n",
        "\n",
        "            df_cols = [\"Filer\", \"Stock\", \"cusip\", \"Title of Class\", \"Market Value\", \n",
        "                      \"Shares Held\", \"Entity Type\", \"Put Call\", \"Investment Discretion\", \n",
        "                      \"Sole\", \"Shared\", \"Source Date\", \"Reporting Period\"]\n",
        "            \n",
        "            download_status_cols = [\"Accession Number\", \"Filer\", \"Source Date\", \"File Name\", \n",
        "                                    \"Download Status\", \"Download Date\", \"Process Status\",\n",
        "                                    \"Time\", \"Source Quarter\", \"Qrank\"]\n",
        "            for r in row:\n",
        "\n",
        "              # Handle missing fields\n",
        "              fields = [r.nameOfIssuer,r.cusip,r.titleOfClass,r.value, r.shrsOrPrnAmt.sshPrnamt,\n",
        "                        r.shrsOrPrnAmt.sshPrnamtType,r.putCall, r.investmentDiscretion,\n",
        "                        r.votingAuthority, r.votingAuthority.Sole,r.votingAuthority.Shared]\n",
        "              row_dict = {}\n",
        "              field_dict = {\"Stock\": r.nameOfIssuer, \n",
        "                              \"cusip\": r.cusip,\n",
        "                              \"Title of Class\": r.titleOfClass, \n",
        "                              \"Market Value\": r.value,\n",
        "                              \"Shares Held\":r.shrsOrPrnAmt.sshPrnamt,\n",
        "                              \"Entity Type\":r.shrsOrPrnAmt.sshPrnamtType, \n",
        "                              \"Put Call\": r.putCall,\n",
        "                              \"Investment Discretion\": r.investmentDiscretion,\n",
        "                              \"Voting Authority\": r.votingAuthority,\n",
        "                              \"Sole\": r.votingAuthority.Sole,\n",
        "                              \"Shared\": r.votingAuthority.Shared, \n",
        "                              }\n",
        "              for col, field in field_dict.items(): \n",
        "                if field:\n",
        "                  row_dict.update({col: field.string})\n",
        "                else: \n",
        "                  row_dict.update({col:\"N/A\"})\n",
        "              each_row.append(row_dict)\n",
        "              \n",
        "            out_df = pd.DataFrame(each_row, columns = df_cols)\n",
        "\n",
        "            # Additional Parameters\n",
        "            out_df['Filer'] = name\n",
        "            if file_meta['Filing Date']:\n",
        "              out_df['Source Date'] = file_meta['Filing Date']\n",
        "            else: \n",
        "              out_df['Source Date'] = \"Not Available\"\n",
        "            out_df['Reporting Period'] = file_meta['Period of Report']\n",
        "\n",
        "            file_name = name + \"_\"+ file_meta['Filing Date']\n",
        "\n",
        "            out_df.to_csv('/content/drive/My Drive/Analytics/13fdata/'+folder+'/'+ file_name + \"_\" + accession_number +\".csv\", index=False)\n",
        "\n",
        "            # create download meta\n",
        "\n",
        "            download_data.append({\"Accession Number\": accession_number, \n",
        "                              \"Filer\": name, \n",
        "                              \"Source Date\": file_meta['Period of Report'],\n",
        "                              \"File Name\": file_name + \"_\" + accession_number +\".csv\",\n",
        "                              \"Download Status\": \"Complete\" , \n",
        "                              \"Download Date\": datetime.datetime.now(),\n",
        "                              \"Process Status\": \"Downloaded\",\n",
        "                              \"Time\": \"\", \n",
        "                              \"Source Quarter\": \"\",\n",
        "                              \"Qrank\": \"\"})\n",
        "            \n",
        "            \n",
        "            print(\"completed file download for \" + accession_number)\n",
        "            f.write(\"completed file download for \" + accession_number)\n",
        "          \n",
        "            download_status_df = pd.DataFrame(download_data, columns = download_status_cols)\n",
        "\n",
        "            # Generate the ranking for the files. \n",
        "            download_status_df['Time'] = pd.to_datetime(download_status_df['Source Date'])\n",
        "            download_status_df['Source Quarter'] = pd.PeriodIndex(download_status_df['Time'], freq='Q').astype(str)\n",
        "            download_status_df['Qrank'] = download_status_df.groupby('Filer')['Time'].rank(ascending=True, method=\"first\")\n",
        "\n",
        "            download_status_df_dict = download_status_df.to_dict(\"records\")\n",
        "            # MONGO DB INSERT HERE - download_status_df insert\n",
        "            db.os13fmeta.insert_many(download_status_df_dict)\n",
        "            '''\n",
        "            if path.exists('/content/drive/My Drive/Analytics/13fdata/' + \"download_status.csv\"):\n",
        "              download_status_df.to_csv('/content/drive/My Drive/Analytics/13fdata/' + \"download_status.csv\", mode='a', header=False, index=False)\n",
        "            else: \n",
        "              download_status_df.to_csv('/content/drive/My Drive/Analytics/13fdata/' + \"download_status.csv\", index=False)\n",
        "          else: \n",
        "            pass # skip the download process'''\n",
        "        else:\n",
        "          print(\"Info table not found or data already downloaded, Skipping\")\n",
        "      except Exception as e:\n",
        "        se = str(e)\n",
        "        print(\"ERROR for Accession Number: \" + accession_number + \"Error:\" + se)\n",
        "        f.write(\"ERROR for Accession Number: \" + accession_number + \"Error: \" + se)\n",
        "        \n",
        "        pass\n",
        "  f.close()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWH6GyEZkzhc"
      },
      "source": [
        "cik_dict =  {'0001009207': 'D.E. Shaw & Company',\n",
        "               '0001029160': 'Soros Fund Management',\n",
        "               '0001037389': 'Renaissance Technologies',\n",
        "               '0001167483': 'Tiger Global Management',\n",
        "               '0001167557': 'AQR',\n",
        "               '0001350694': 'Bridgewater Associates',\n",
        "               '0001387322': 'Whale Rock Capital Management',\n",
        "               '0001410833': 'Night Owl Capital Management',\n",
        "               '0001423053': 'Citadel Advisors',\n",
        "               '0001537530': 'Scge Management',\n",
        "               '0001553936': 'Tybourne Capital Management',\n",
        "               '0001577133': 'Greenwoods Asset Management',\n",
        "               '0001649339': 'Scion Asset Management',\n",
        "               '0001510281': 'Saba Capital Management',\n",
        "               '0001061165': 'Lone Pine Capital',\n",
        "               '0001061768': 'The Baupost Group',\n",
        "               '0001103804': 'Viking Global Investors',\n",
        "               #'0001048445': 'Elliott Management Corp',\n",
        "               '0001315765': 'Cedar Rock Capital Limited',\n",
        "               '0001656456': 'Appaloosa LP',\n",
        "               '0001273087': 'Millennium Management LLC',\n",
        "               '0000909661': 'Farallon Capital Management',\n",
        "               '0001627436': 'Sylebra HK',\n",
        "               '0001476179':'Firsthand Capital Management',\n",
        "               '0001389933': 'DAFNA Capital Management',\n",
        "               '0001104329': 'CrossLink Capital Inc',\n",
        "               '0001671657': 'Dorsey Asset Management',\n",
        "               '0001599731': 'Atika Capital Management',\n",
        "               '0001067983': 'Berkshire Hathaway'\n",
        "\n",
        "  }\n",
        "\n",
        "############################################################\n",
        "\n",
        "  # Historical Download - RUN THIS CODE ONLY ONE TIME \n",
        "  cik_df = pd.read_csv('/content/drive/My Drive/Analytics/13fdata/cik13ffilers.csv')\n",
        "  cik_df['CIK'] = cik_df['CIK'].astype(str).str.zfill(10)\n",
        "  x = cik_df[['CIK', 'COMPANY']].to_json(orient='records')\n",
        "  parsed = json.loads(x)\n",
        "  cik_dict = {}\n",
        "  for p in parsed:\n",
        "    cik_dict.update({p['CIK']:p['COMPANY']})\n",
        "\n",
        "#############################################################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXhvN7rF7NRw"
      },
      "source": [
        "def DailyPull():\n",
        "  import datetime\n",
        "  import requests\n",
        "  import pandas as pd\n",
        "  import json\n",
        "\n",
        "  # determine yesterday date  \n",
        "  today = datetime.date.today()\n",
        "  yesterday = today - datetime.timedelta(days=2)\n",
        "  print(yesterday)\n",
        "  year = yesterday.strftime('%Y')\n",
        "  month = yesterday.strftime('%m')\n",
        "  day = yesterday.strftime('%d')\n",
        "  date = year + '-' + month + '-' + day\n",
        "\n",
        "  # Daily pull\n",
        "  url= 'https://www.sec.gov/Archives/edgar/full-index/2020/QTR4/master.idx'\n",
        "  lines = requests.get(url).content.decode(\"utf-8\", \"ignore\").splitlines()\n",
        "  records = [tuple(line.split('|')) for line in lines[11:]]\n",
        "  filers_df = pd.DataFrame(records, columns=[\"CIK\", \"COMPANY\", \"FORM\", \"DATE\", \"URL\"])\n",
        "  filers_13f_df = filers_df[filers_df[\"FORM\"]== \"13F-HR\"]\n",
        "  filers_13f_df['CIK'] = filers_13f_df['CIK'].astype(str).str.zfill(10)\n",
        "  to_be_checked_filers_df = filers_13f_df[filers_13f_df[\"DATE\"] > date]\n",
        "\n",
        "  # convert to dict\n",
        "  filers_json = to_be_checked_filers_df[['CIK', 'COMPANY']].to_json(orient='records')\n",
        "  parsed = json.loads(filers_json)\n",
        "  cik_dict = {}\n",
        "  for p in parsed:\n",
        "    p['COMPANY'] = p['COMPANY'].replace(\"/\", \"\")\n",
        "    cik_dict.update({p['CIK']:p['COMPANY']})\n",
        "\n",
        "  print(cik_dict)\n",
        "  # call data-downloader\n",
        "  get13FData(cik_dict, \"Q420\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNjMegrlwFWA"
      },
      "source": [
        "def DataPipeline():\n",
        "\n",
        "  # download data\n",
        "  # postprocess # 1 - tier 1 transformations\n",
        "  # postprocess # 2 - tier 2 transformations\n",
        "\n",
        "  # define contants\n",
        "\n",
        "  #path_downloaded = '/content/drive/My Drive/Analytics/13fdata/data/'\n",
        "  path_downloaded = '/content/drive/My Drive/Analytics/13fdata/'\n",
        "\n",
        "  # get meta file\n",
        "  meta_df = pd.read_csv(path_downloaded +'download_status.csv')\n",
        "  #files = list(meta_df[(meta_df['Process Status'] == \"Downloaded\")]['File Name'])\n",
        "  files = fileNameExtract()\n",
        "  \n",
        "  # postprocess # 1\n",
        "  #Parallel(n_jobs=4, backend='multiprocessing')(delayed(postProcess)(f) for f in files)\n",
        "  \n",
        "  for f in files:\n",
        "    result = postProcess(f, \"Q420\")\n",
        "  '''\n",
        "  # postprocess # 2\n",
        "  # Reset Ranks\n",
        "  meta_df['Time'] = pd.to_datetime(meta_df['Source Date'])\n",
        "  meta_df['Qrank'] = meta_df.groupby('Filer')['Time'].rank(ascending=True, method=\"first\")\n",
        "  # Update the csv\n",
        "  #meta_df.to_csv('/content/drive/My Drive/Analytics/13fdata/data/download_status.csv', index=False)\n",
        "  meta_df.to_csv('/content/drive/My Drive/Analytics/13fdata/download_status.csv', index=False)\n",
        "  \n",
        "  files_to_be_processed = meta_df[meta_df[\"Process Status\"] == \"Base Processed\"][[\"Filer\", \"File Name\", \"Qrank\"]]\n",
        "  for f in tqdm(list(files_to_be_processed[\"Filer\"].unique())):\n",
        "    chunk = files_to_be_processed[files_to_be_processed[\"Filer\"] == f][[\"File Name\", \"Qrank\"]]\n",
        "    print (chunk[\"Qrank\"].max())\n",
        "    for i in range(int(chunk[\"Qrank\"].min()), int(chunk[\"Qrank\"].max()+1)):\n",
        "      if i == 1:\n",
        "        print(chunk[chunk[\"Qrank\"]==i][\"File Name\"].iloc[0])\n",
        "        first_file_df = initialFile(chunk[chunk[\"Qrank\"]==i][\"File Name\"].iloc[0])\n",
        "      elif chunk[\"Qrank\"].min() == chunk[\"Qrank\"].max():\n",
        "        latest_file_chunk = meta_df[(meta_df['Filer']==f) & (meta_df['Process Status'] == 'Latest File')][['File Name', 'Qrank']]\n",
        "        previous_file = latest_file_chunk[\"File Name\"].iloc[0]\n",
        "        current_file =  chunk[chunk[\"Qrank\"]==i][\"File Name\"].iloc[0]\n",
        "        #print(\"Previous File: \", previous_file)\n",
        "        #print(\"Current File: \", current_file)\n",
        "        processed_df = qoqChange(previous_file, current_file)\n",
        "      else:\n",
        "        print(chunk[chunk[\"Qrank\"]==i][\"File Name\"] + \" is the {0} file\".format(i))\n",
        "        #latest_file_chunk = meta_df[(meta_df['Filer']==f) & (meta_df['Process Status'] == 'Latest File')][['File Name', 'Qrank']]\n",
        "        #previous_file = latest_file_chunk[\"File Name\"].iloc[0]\n",
        "        previous_file = chunk[chunk[\"Qrank\"]==i-1][\"File Name\"].iloc[0]\n",
        "        current_file =  chunk[chunk[\"Qrank\"]==i][\"File Name\"].iloc[0]\n",
        "        processed_df = qoqChange(previous_file, current_file)\n",
        "        #print(\"Previous File: \", previous_file)\n",
        "        #print(\"Current File: \", current_file)\n",
        "\n",
        "        '''"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J2zIgO1wVac"
      },
      "source": [
        "def postProcess(fileName, q):\n",
        "  folder = q+\"data\"\n",
        "  print (\"Processing: \" + fileName)\n",
        "  # get cusip from local file else run cusip_lookup\n",
        "  p = '/content/drive/My Drive/Analytics/13fdata/'\n",
        "  #p1 = '/content/drive/My Drive/Analytics/13fdata/'\n",
        "  #df = pd.read_csv(p+fileName) # read fileName\n",
        "  #df = pd.read_csv(p1+\"newdata/\"+fileName) # Read filename for newdata\n",
        "  df = pd.read_csv(p+folder+'/' + fileName)\n",
        "  download_status_df = pd.read_csv(p+\"download_status.csv\")\n",
        "  try:\n",
        "    # Calculate metrics\n",
        "    df[\"Total Market Value\"] = df[\"Market Value\"]*1000\n",
        "    df[\"Average Price\"] = round(df[\"Total Market Value\"] / df[\"Shares Held\"], 2)\n",
        "    df[\"Reporting Period\"] = pd.to_datetime(df[\"Reporting Period\"])\n",
        "    df[\"Source Date\"] = pd.to_datetime(df[\"Source Date\"])\n",
        "    df[\"Reporting Quarter\"] = pd.PeriodIndex(df['Reporting Period'], freq='Q')\n",
        "    df[\"Source Quarter\"] = pd.PeriodIndex(df['Source Date'], freq='Q')\n",
        "    Total_Market_Value = df[\"Total Market Value\"].sum()\n",
        "    df[\"Percent of Portfolio\"] = round((df[\"Total Market Value\"] / Total_Market_Value)*100, 2)\n",
        "    df[\"Rank\"] = df[\"Percent of Portfolio\"].rank(method=\"max\", ascending=False)\n",
        "\n",
        "\n",
        "    # Column Rename and change dtypes to str\n",
        "    df.rename(columns = {'cusip': 'CUSIP', 'Stock': 'Name'}, inplace=True)\n",
        "    df['CUSIP'] = df['CUSIP'].astype('str')\n",
        "    \n",
        "    #cusip_lkp_df = pd.read_csv(p+\"CUSIP_LKP.csv\", usecols=[\"SYMBOL\", \"CUSIP\"])\n",
        "    cusip_md = getcusip_mdb()\n",
        "    cusip_lkp_df = pd.DataFrame(cusip_md)\n",
        "    cusip_lkp_df = cusip_lkp_df[[\"SYMBOL\", \"CUSIP\"]]\n",
        "    cusip_lkp_df['CUSIP'] = cusip_lkp_df['CUSIP'].astype('str')\n",
        "\n",
        "    # Lookup CUSIP\n",
        "\n",
        "    determine_cusip = list(df[\"CUSIP\"]) # extract cusip to be lookedup\n",
        "    # Find the ones that are available in master cusip lookup\n",
        "    available_cusip = cusip_lkp_df[cusip_lkp_df['CUSIP'].isin(determine_cusip)]\n",
        "    available_cusip_list = list(available_cusip[\"CUSIP\"])\n",
        "\n",
        "    # If the resulting DF is not empty - i.e. Then find the ones missing \n",
        "    if available_cusip.shape[0] > 0:\n",
        "      cusip_to_find = [c for c in determine_cusip if c not in available_cusip_list]\n",
        "      cusip_to_find = list(np.unique(cusip_to_find))\n",
        "      for cf in cusip_to_find:\n",
        "        print(\"calling external for: \" + cf)\n",
        "        cusip_lookup(cf) # find the missing ones and insert it in the master\n",
        "    else:\n",
        "      pass \n",
        "\n",
        "    # Reload refreshed cusip_lkp\n",
        "    #ref_cusip_lkp_df = pd.read_csv(p+\"CUSIP_LKP.csv\", usecols=[\"SYMBOL\", \"CUSIP\"])\n",
        "    ref_cusip_md = getcusip_mdb()\n",
        "    ref_cusip_lkp_df = pd.DataFrame(ref_cusip_md)\n",
        "    ref_cusip_lkp_df = ref_cusip_lkp_df[[\"SYMBOL\", \"CUSIP\"]]\n",
        "    result = pd.merge(df, ref_cusip_lkp_df, on=\"CUSIP\", how=\"inner\" )\n",
        "\n",
        "    # write the results in postprocess\n",
        "    result.to_csv(p+\"post1data/\"+fileName, index=False)\n",
        "\n",
        "    # Update process status\n",
        "    #download_status_df.loc[download_status_df[\"File Name\"] == fileName, \"Process Status\"] = \"Base Processed\"\n",
        "    #download_status_df.to_csv(p+'download_status.csv', index=False)\n",
        "    updateFileStatus(fileName, \"Base Processed\")\n",
        "    print (\"Completed Processing: \" + fileName)\n",
        "\n",
        "    return result\n",
        "  except Exception as e:\n",
        "    se = str(e)\n",
        "    # Update process status\n",
        "    #download_status_df.loc[download_status_df[\"File Name\"] == fileName, \"Process Status\"] = \"Error in Processing\"\n",
        "    updateFileStatus(fileName, \"Error in Processing\")\n",
        "    #download_status_df.to_csv(p+'download_status.csv', index=False)\n",
        "    print(\"ERROR in processing file: \" + fileName + \"Error:\" + se)\n",
        "    return \"Error\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMWlG-PUUZ_v"
      },
      "source": [
        "def qoqChange(fileName_n, fileName_n1):\n",
        "  p1 = '/content/drive/My Drive/Analytics/13fdata/finaldata/'\n",
        "  p ='/content/drive/My Drive/Analytics/13fdata/Q420finaldata/' # change to final data\n",
        "  p2 = '/content/drive/My Drive/Analytics/13fdata/post1data/'\n",
        "\n",
        "  \n",
        "  #read meta file\n",
        "  #download_status_df = pd.read_csv(path_downloaded+\"download_status.csv\")\n",
        "  try:\n",
        "    #file1EmptyCheck = check_empty(fileName_n) #78\n",
        "    #file2EmptyCheck = check_empty(fileName_n1) #79\n",
        "    file1EmptyCheck = 1\n",
        "    file2EmptyCheck = 1\n",
        "    if file1EmptyCheck == 1 & file2EmptyCheck == 1: # check if file is empty\n",
        "      \n",
        "      df_n = pd.read_csv(p1+fileName_n)\n",
        "      df_n1 = pd.read_csv(p2+fileName_n1)\n",
        "\n",
        "      # ensure changes to CUSIP for merge\n",
        "      df_n['CUSIP'] = df_n['CUSIP'].astype('str')\n",
        "      df_n1['CUSIP'] = df_n1['CUSIP'].astype('str')\n",
        "\n",
        "      # Calculate Change in Shares, Calculate Change Status\n",
        "      dfn1 = df_n1.groupby(['Filer','CUSIP', 'SYMBOL', 'Name', 'Entity Type', 'Reporting Period', 'Reporting Quarter', 'Source Date'], as_index=False)[['Shares Held', 'Total Market Value']].sum()\n",
        "      dfn = df_n.groupby(['Filer','CUSIP', 'SYMBOL', 'Name', 'Entity Type', 'Reporting Period', 'Reporting Quarter', 'Source Date'], as_index=False)[['Shares Held', 'Total Market Value']].sum()\n",
        "      \n",
        "      # identify New or Sold All CUSIPS\n",
        "      result = pd.merge(dfn, dfn1, on=\"CUSIP\", how=\"outer\", suffixes=('_Before', '_Current'), indicator=True)\n",
        "      result['Change Status'] = ''\n",
        "\n",
        "      result.loc[result['_merge'] == 'right_only', [\"Change Status\"]] = 'New'\n",
        "      result.loc[result['_merge'] == 'left_only', [\"Change Status\"]] = 'Sold All'\n",
        "\n",
        "\n",
        "      # Extract New, Sold All\n",
        "      df_lo = result[result['_merge'] == 'left_only']\n",
        "      df_ro = result[result['_merge'] == 'right_only']\n",
        "\n",
        "      # Handle Common CUSIPs\n",
        "      df_bo = pd.merge(dfn, dfn1, on=\"CUSIP\", how=\"inner\", suffixes=('_Before', '_Current'), indicator=True)\n",
        "\n",
        "      df_bo['Change Status'] = np.where(df_bo['Shares Held_Before']< df_bo['Shares Held_Current'], \"Added\",\\\n",
        "                                        np.where(df_bo['Shares Held_Before']>df_bo['Shares Held_Current'], \"Reduced\", \\\n",
        "                                        np.where(df_bo['Shares Held_Before']==df_bo['Shares Held_Current'], \"No Change\",\\\n",
        "                                                \"NA\" )))\n",
        "\n",
        "      # calculate changes in shares for for both\n",
        "      df_bo[\"Changes in Shares Held\"] = df_bo[\"Shares Held_Current\"] - df_bo[\"Shares Held_Before\"]\n",
        "      df_bo[\"Changes in Market Value\"] = df_bo[\"Total Market Value_Current\"] - df_bo[\"Total Market Value_Before\"]\n",
        "\n",
        "      # Set changes to new buys\n",
        "      df_ro['Changes in Shares Held'] = df_ro['Shares Held_Current']\n",
        "      df_ro['Changes in Market Value'] = df_ro['Total Market Value_Current']\n",
        "\n",
        "      # Set changes to Sells\n",
        "      df_lo['Changes in Shares Held'] = df_lo['Shares Held_Before'] * -1\n",
        "      df_lo['Changes in Market Value'] = df_lo['Total Market Value_Before'] * -1\n",
        "\n",
        "      # drop and rename columns\n",
        "      df_lo.drop([col for col in df_lo.columns if 'Current' in col],axis=1, inplace=True)\n",
        "      df_lo.columns = df_lo.columns.str.replace(r'_Before$', '')\n",
        "      df_lo.drop(columns=['_merge'], inplace = True)\n",
        "      df_ro.drop([col for col in df_ro.columns if 'Before' in col],axis=1, inplace=True)\n",
        "      df_ro.columns = df_ro.columns.str.replace(r'_Current$', '')\n",
        "      df_ro.drop(columns=['_merge'], inplace = True)\n",
        "      df_bo.drop([col for col in df_bo.columns if 'Before' in col],axis=1, inplace=True)\n",
        "      df_bo.columns = df_bo.columns.str.replace(r'_Current$', '')\n",
        "      df_bo.drop(columns=['_merge'], inplace = True)\n",
        "\n",
        "      # concat all the dfs\n",
        "\n",
        "      updated_df = pd.concat([df_lo, df_ro, df_bo])\n",
        "\n",
        "\n",
        "      # Calculate Derived Metrics\n",
        "      updated_df['Average Price'] = updated_df['Total Market Value'] / updated_df['Shares Held']\n",
        "      updated_df['Percent of Portfolio'] = updated_df['Total Market Value'] / updated_df['Total Market Value'].sum()\n",
        "      updated_df['Rank'] = updated_df['Total Market Value'].rank(method='max', ascending=False).astype(int)\n",
        "\n",
        "\n",
        "      updated_df.to_csv(p+fileName_n1, index=False)\n",
        "      \n",
        "      # Update process status\n",
        "\n",
        "      #download_status_df.loc[download_status_df[\"File Name\"] == fileName_n1, \"Process Status\"] = \"Latest File\"\n",
        "      #download_status_df.loc[download_status_df[\"File Name\"] == fileName_n, \"Process Status\"] = \"QoQ Processed\"\n",
        "      updateFileStatus(fileName_n1, \"Latest File\")\n",
        "      updateFileStatus(fileName_n, \"QoQ Processed\")\n",
        "      #download_status_df.to_csv(path_downloaded+'download_status.csv', index=False)\n",
        "      print('Completed ' + fileName_n1)\n",
        "      return \"Success\"\n",
        "    else: \n",
        "      print(\"Skipping files: \", fileName_n, fileName_n1, file1EmptyCheck, file2EmptyCheck)\n",
        "      if file2EmptyCheck != 1:\n",
        "        #download_status_df.loc[download_status_df[\"File Name\"] == fileName_n1, \"Process Status\"] = \"Empty File\"\n",
        "        updateFileStatus(fileName_n1, \"Empty File\")\n",
        "      else:\n",
        "        # add required columns\n",
        "        dfn = pd.read_csv(p2+fileName_n1)\n",
        "        cols = ['Title of Class','Market Value', 'Put Call', 'Investment Discretion', 'Sole', 'Shared', 'Source Quarter']\n",
        "        dfn.drop(columns=cols, axis=1, inplace=True)\n",
        "        dfn['Changes in Shares Held'] = None\n",
        "        dfn['Changes in Market Value'] = None\n",
        "        dfn['Change Status'] = \"NA\"\n",
        "        dfn.to_csv(p+fileName_n1, index=False) \n",
        "        #download_status_df.loc[download_status_df[\"File Name\"] == fileName_n1, \"Process Status\"] = \"Latest File\"\n",
        "        updateFileStatus(fileName_n1, \"Latest File\")\n",
        "      if file1EmptyCheck != 1:\n",
        "        \n",
        "        # add required columns\n",
        "        dfn = pd.read_csv(p1+fileName_n)\n",
        "        dfn.drop(columns=cols, axis=1, inplace=True)\n",
        "        dfn['Changes in Shares Held'] = None\n",
        "        dfn['Changes in Market Value'] = None\n",
        "        dfn['Change Status'] = None\n",
        "        dfn['Average Price'] = None\n",
        "        dfn['Percent of Portfolio'] = None\n",
        "        dfn['Rank'] = 0\n",
        "        dfn.to_csv(p+fileName_n, index=False)\n",
        "        #download_status_df.loc[download_status_df[\"File Name\"] == fileName_n, \"Process Status\"] = \"Empty File\"\n",
        "        updateFileStatus(fileName_n, \"Empty File\")\n",
        "      else: \n",
        "        #download_status_df.loc[download_status_df[\"File Name\"] == fileName_n, \"Process Status\"] = \"QoQ Processed\"\n",
        "        updateFileStatus(fileName_n, \"QoQ Processed\")  \n",
        "      #download_status_df.to_csv(path_downloaded+'download_status.csv', index=False)\n",
        "      return \"Error\"\n",
        "  except Exception as e:\n",
        "    se = str(e)\n",
        "    print(\"ERROR in processing file: \" + fileName_n1 + \"Error:\" + se)\n",
        "    # Update process status\n",
        "    #download_status_df.loc[download_status_df[\"File Name\"] == fileName_n1, \"Process Status\"] = \"Error in QoQ\"\n",
        "    updateFileStatus(fileName_n1, \"Error in QoQ\")\n",
        "    #download_status_df.to_csv(path_downloaded+'download_status.csv', index=False)\n",
        "    return \"Error\"\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-pEAtPU5-uZ"
      },
      "source": [
        "def initialFile(fileName):\n",
        "  p = '/content/drive/My Drive/Analytics/13fdata/post1data/'\n",
        "  p1 ='/content/drive/My Drive/Analytics/13fdata/Q420finaldata/'\n",
        "  try:\n",
        "    #file1EmptyCheck = check_empty(fileName) # remove this check\n",
        "    file1EmptyCheck = 1\n",
        "    if file1EmptyCheck == 1:\n",
        "      df = pd.read_csv(p+fileName)\n",
        "      dfn = df.groupby(['Filer','CUSIP', 'SYMBOL', 'Name', 'Entity Type', 'Reporting Period', 'Reporting Quarter', 'Source Date'], as_index=False)[['Shares Held', 'Total Market Value']].sum()\n",
        "      dfn['Changes in Shares Held'] = None\n",
        "      dfn['Changes in Market Value'] = None\n",
        "      dfn['Change Status'] = 'New'\n",
        "      dfn['Average Price'] = dfn['Total Market Value'] / dfn['Shares Held']\n",
        "      dfn['Percent of Portfolio'] = dfn['Total Market Value'] / dfn['Total Market Value'].sum()\n",
        "      dfn['Rank'] = dfn['Total Market Value'].rank(method='max', ascending=False).astype(int)\n",
        "      \n",
        "      updateFileStatus(fileName, \"Initial File\")\n",
        "      #meta_df.loc[meta_df[\"File Name\"] == fileName, \"Process Status\"] = \"Initial File\"\n",
        "\n",
        "      dfn.to_csv(p1+fileName, index=False)\n",
        "      print(\"Completed Intial File\")\n",
        "    else: \n",
        "      print(\"Empty File. Skipping\")\n",
        "      updateFileStatus(fileName, \"Initial File\")\n",
        "      #meta_df.loc[meta_df[\"File Name\"] == fileName, \"Process Status\"] = \"Initial File\"\n",
        "      #meta_df.to_csv(path_downloaded+\"download_status\", index=False)\n",
        "  except Exception as e:\n",
        "    se = str(e)\n",
        "    print(\"ERROR in processing file: \" + fileName + \"Error:\" + se)\n",
        "    # Update process status\n",
        "    #meta_df.loc[meta_df[\"File Name\"] == fileName, \"Process Status\"] = \"Error in QoQ\"\n",
        "    #meta_df.to_csv(path_downloaded+'download_status.csv', index=False)\n",
        "    updateFileStatus(fileName, \"Error in QoQ\")\n",
        "    return \"Error\"\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws2svwfJF-4D"
      },
      "source": [
        "# Function to merge final data csv files\n",
        "def mergeData(xy):\n",
        "  # accepts the list of files to be processed\n",
        "\n",
        "  files = []\n",
        "  p = '/content/drive/My Drive/Analytics/13fdata/post1data/'\n",
        "  # r=root, d=directories, f = files\n",
        "  '''\n",
        "  for r, d, f in os.walk(p):\n",
        "      for file in f:\n",
        "          if '.csv' in file:\n",
        "              files.append(os.path.join(r, file))'''\n",
        "\n",
        "  all_df = []\n",
        "  for f in xy:\n",
        "    fileCheck = check_empty(f)\n",
        "    if fileCheck == 1:\n",
        "      df = pd.read_csv(p+f, sep=',')\n",
        "      df['file'] = f.split('/')[-1]\n",
        "      all_df.append(df)\n",
        "    else:\n",
        "      print(f, \" is Empty\")\n",
        "\n",
        "  \n",
        "\n",
        "  merged_df = pd.concat(all_df)\n",
        "  print(merged_df.shape)\n",
        "  print(merged_df.columns)\n",
        "  merged_df.to_csv('/content/drive/My Drive/Analytics/13fdata/marts/Q420FilerBase.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW1m1jxYXHWI"
      },
      "source": [
        "# function to generate Q420FilerBase Analysis\n",
        "def filerBaseAnalysis():\n",
        "  all_df =[]\n",
        "  p = '/content/drive/My Drive/Analytics/13fdata/post1data/'\n",
        "  files = fileNameExtract() # Base Processed Files Only\n",
        "  for f in tqdm(files):\n",
        "    df = pd.read_csv(p+f, sep=',', usecols=[\"Filer\", \"Name\", \"CUSIP\", \"Market Value\", \"Shares Held\", \"Entity Type\", \"Put Call\", \"Reporting Quarter\", \"Reporting Period\",\\\n",
        "                                            \"Total Market Value\", \"Average Price\", \"Percent of Portfolio\", \"Rank\", \"SYMBOL\"])\n",
        "    #df['file'] = f.split('/')[-1]\n",
        "    all_df.append(df)\n",
        "\n",
        "  merged_df = pd.concat(all_df)\n",
        "  merged_df.to_csv('/content/drive/My Drive/Analytics/13fdata/marts/Q420FilerBase.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI4-SpEMafp2"
      },
      "source": [
        "# function to generate Q420FilerBase Analysis\n",
        "def filerFinalAnalysis():\n",
        "  all_df =[]\n",
        "  files = []\n",
        "  p = '/content/drive/My Drive/Analytics/13fdata/Q420finaldata/'\n",
        "  file1 = fileNameExtract(\"Latest File\", \"2020Q3\") # Q32020 Processed Files Only\n",
        "  file2 = fileNameExtract(\"Initial File\", \"2020Q3\")\n",
        "  \n",
        "  for f1 in file1:\n",
        "    files.append(f1[\"File Name\"])\n",
        "  for f2 in file2:\n",
        "    files.append(f2[\"File Name\"]) \n",
        "  \n",
        "  for f in tqdm(files):\n",
        "    df = pd.read_csv(p+f, sep=',')\n",
        "    all_df.append(df)\n",
        "\n",
        "\n",
        "  merged_df = pd.concat(all_df)\n",
        "  merged_df.to_csv('/content/drive/My Drive/Analytics/13fdata/marts/Q32020FinalAnalysis.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9aAlE29CB_i"
      },
      "source": [
        "# code for QoQ \n",
        "\n",
        "def qoqInitiate():\n",
        "  '''\n",
        "  1. Get all files marked as Base Processed and Current Quarter and get the filers\n",
        "  2. For each filer, check one and only 1 Base Processed\n",
        "  3. For each filer, get the file Marked Latest File from FinalData\n",
        "  4. Pass these 2 files to QoQ Process\n",
        "  5. Land these files in a Q420 Final Data Folder\n",
        "  '''\n",
        "\n",
        "  db = get_mongo_client()\n",
        "  files = fileNameExtract(\"Base Processed\", \"2020Q3\")\n",
        "\n",
        "  for f in tqdm(files):\n",
        "    last_file_data = db.os13fmeta.find({\"$and\": [{\"Filer\": f[\"Filer\"]},{\"Process Status\": \"Latest File\"}]})\n",
        "    last_file = list(last_file_data)\n",
        "    try:\n",
        "      if len(last_file) > 0:\n",
        "        previous_file = last_file[0][\"File Name\"]\n",
        "        current_file = f[\"File Name\"] \n",
        "        # check if Latest File exists\n",
        "        p = '/content/drive/My Drive/Analytics/13fdata/finaldata/'\n",
        "        df = pd.read_csv(p+previous_file)\n",
        "        print(df.shape)\n",
        "        processed_df = qoqChange(previous_file, current_file)\n",
        "      else: \n",
        "        current_file = f[\"File Name\"]\n",
        "        # call Initial File\n",
        "        processed_df = initialFile(current_file)\n",
        "    except Exception as e:\n",
        "      se = str(e)\n",
        "      print(se)  "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MCGfcUFo3Oo",
        "outputId": "f207dc1a-d710-4c5c-e534-676510c0708f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "723760ac658c48fba003d3a2d56b86d6",
            "4f487002a0334626a1f46b06c5199511",
            "ab62c10d357e4d91867c7c34d9bf898f",
            "d161b5c0cc834abfaf82241ada82e87d",
            "f253b949eb1a400c9944a1d359f89f9e",
            "70a4e807b98b4d05b8e35b87d5c37aba",
            "3068b6ec9ea34991b853f543e21d0acf",
            "fcab2407b23046269670fd4912b8a48c"
          ]
        }
      },
      "source": [
        "#DailyPull()\n",
        "# Check Downloaded Empty Files\n",
        "db = get_mongo_client()\n",
        "file_records = fileNameExtract(\"Base Processed\", \"2020Q3\")\n",
        "print(file_records)\n",
        "files = []\n",
        "for f in file_records:\n",
        "  files.append(f[\"File Name\"])\n",
        "#x = Parallel(n_jobs=4, backend='multiprocessing')(delayed(postProcess)(f, \"Q420\") for f in tqdm(files))\n",
        "qoqInitiate()\n",
        "#filerBaseAnalysis()\n",
        "#filerFinalAnalysis()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'File Name': 'EXANE DERIVATIVES_2020-10-06_0001623883-20-000008.csv', 'Filer': 'EXANE DERIVATIVES'}, {'File Name': 'FRANKLIN STREET ADVISORS INC NC_2020-10-21_0001010873-20-000003.csv', 'Filer': 'FRANKLIN STREET ADVISORS INC NC'}, {'File Name': 'CORTLAND ASSOCIATES INCMO_2020-10-21_0001567619-20-018044.csv', 'Filer': 'CORTLAND ASSOCIATES INCMO'}, {'File Name': 'SWARTHMORE GROUP INC_2020-10-21_0001062993-20-005079.csv', 'Filer': 'SWARTHMORE GROUP INC'}, {'File Name': 'INGALLS & SNYDER LLC_2020-10-21_0001041885-20-000023.csv', 'Filer': 'INGALLS & SNYDER LLC'}, {'File Name': 'COMMUNITY TRUST & INVESTMENT CO_2020-10-21_0001047142-20-000005.csv', 'Filer': 'COMMUNITY TRUST & INVESTMENT CO'}, {'File Name': 'CenturyLink Investment Management Co_2020-10-21_0001054522-20-000009.csv', 'Filer': 'CenturyLink Investment Management Co'}, {'File Name': 'JAG CAPITAL MANAGEMENT, LLC_2020-10-21_0001080374-20-000005.csv', 'Filer': 'JAG CAPITAL MANAGEMENT, LLC'}, {'File Name': 'HENDLEY & CO INC_2020-10-21_0001084207-20-000004.csv', 'Filer': 'HENDLEY & CO INC'}, {'File Name': 'BUCKINGHAM CAPITAL MANAGEMENT INC_2020-10-21_0001089212-20-000005.csv', 'Filer': 'BUCKINGHAM CAPITAL MANAGEMENT INC'}, {'File Name': 'CAPITAL CITY TRUST COFL_2020-10-21_0001062993-20-005075.csv', 'Filer': 'CAPITAL CITY TRUST COFL'}, {'File Name': 'LYNCH & ASSOCIATESIN_2020-10-21_0001108965-20-000004.csv', 'Filer': 'LYNCH & ASSOCIATESIN'}, {'File Name': 'BOENNING & SCATTERGOOD, INC._2020-10-21_0000012933-20-000009.csv', 'Filer': 'BOENNING & SCATTERGOOD, INC.'}, {'File Name': 'Country Club Trust Company, n.a._2020-10-21_0001085146-20-002599.csv', 'Filer': 'Country Club Trust Company, n.a.'}, {'File Name': 'Ziegler Capital Management, LLC_2020-10-21_0001085146-20-002596.csv', 'Filer': 'Ziegler Capital Management, LLC'}, {'File Name': 'Ledyard National Bank_2020-10-21_0001310658-20-000004.csv', 'Filer': 'Ledyard National Bank'}, {'File Name': 'Canal Insurance CO_2020-10-21_0001313473-20-000009.csv', 'Filer': 'Canal Insurance CO'}, {'File Name': 'LOCUST WOOD CAPITAL ADVISERS, LLC_2020-10-21_0001349434-20-000004.csv', 'Filer': 'LOCUST WOOD CAPITAL ADVISERS, LLC'}, {'File Name': 'Regis Management CO LLC_2020-10-21_0001352776-20-000012.csv', 'Filer': 'Regis Management CO LLC'}, {'File Name': 'ALPHA WINDWARD LLC_2020-10-21_0001353219-20-000004.csv', 'Filer': 'ALPHA WINDWARD LLC'}, {'File Name': 'Gryphon International Investment CORP_2020-10-21_0001062993-20-005081.csv', 'Filer': 'Gryphon International Investment CORP'}, {'File Name': 'Fulcrum Asset Management LLP_2020-10-21_0001085146-20-002598.csv', 'Filer': 'Fulcrum Asset Management LLP'}, {'File Name': 'Evensky & Katz LLC_2020-10-21_0001357867-20-000005.csv', 'Filer': 'Evensky & Katz LLC'}, {'File Name': 'Financial Sense Advisors, Inc._2020-10-21_0001085146-20-002590.csv', 'Filer': 'Financial Sense Advisors, Inc.'}, {'File Name': 'Round Table Services, LLC_2020-10-21_0001606587-20-001090.csv', 'Filer': 'Round Table Services, LLC'}, {'File Name': 'Harrington Investments, INC_2020-10-21_0001386364-20-000004.csv', 'Filer': 'Harrington Investments, INC'}, {'File Name': 'Paragon Capital Management LLC_2020-10-21_0001388437-20-000006.csv', 'Filer': 'Paragon Capital Management LLC'}, {'File Name': 'Pineno Levin & Ford Asset Management, Inc._2020-10-21_0001390205-20-000004.csv', 'Filer': 'Pineno Levin & Ford Asset Management, Inc.'}, {'File Name': 'Vision Capital Management, Inc._2020-10-21_0001417889-20-000006.csv', 'Filer': 'Vision Capital Management, Inc.'}, {'File Name': 'WealthTrust Axiom LLC_2020-10-21_0001085146-20-002593.csv', 'Filer': 'WealthTrust Axiom LLC'}, {'File Name': 'Focused Investors LLC_2020-10-21_0001426398-20-000011.csv', 'Filer': 'Focused Investors LLC'}, {'File Name': 'NORTHWEST INVESTMENT COUNSELORS, LLC_2020-10-21_0001420506-20-001075.csv', 'Filer': 'NORTHWEST INVESTMENT COUNSELORS, LLC'}, {'File Name': 'First Heartland Consultants, Inc._2020-10-21_0001214659-20-008769.csv', 'Filer': 'First Heartland Consultants, Inc.'}, {'File Name': 'AEGON USA Investment Management, LLC_2020-10-21_0001454937-20-000010.csv', 'Filer': 'AEGON USA Investment Management, LLC'}, {'File Name': 'Brouwer & Janachowski, LLC_2020-10-21_0001483394-20-000006.csv', 'Filer': 'Brouwer & Janachowski, LLC'}, {'File Name': 'Mizuho Trust & Banking Co., Ltd._2020-10-21_0001512575-20-000004.csv', 'Filer': 'Mizuho Trust & Banking Co., Ltd.'}, {'File Name': 'ROCKY MOUNTAIN ADVISERS, LLC_2020-10-21_0001512779-20-000008.csv', 'Filer': 'ROCKY MOUNTAIN ADVISERS, LLC'}, {'File Name': 'Camarda Financial Advisors, LLC_2020-10-21_0001536444-20-000004.csv', 'Filer': 'Camarda Financial Advisors, LLC'}, {'File Name': 'Consolidated Investment Group LLC_2020-10-21_0001104659-20-116668.csv', 'Filer': 'Consolidated Investment Group LLC'}, {'File Name': 'Spectrum Financial Alliance Ltd LLC_2020-10-21_0001566531-20-000004.csv', 'Filer': 'Spectrum Financial Alliance Ltd LLC'}, {'File Name': 'Edge Wealth Management LLC_2020-10-21_0001567163-20-000004.csv', 'Filer': 'Edge Wealth Management LLC'}, {'File Name': 'Bank OZK_2020-10-21_0000950123-20-010347.csv', 'Filer': 'Bank OZK'}, {'File Name': 'Cerebellum GP, LLC_2020-10-21_0001578472-20-000005.csv', 'Filer': 'Cerebellum GP, LLC'}, {'File Name': 'Hefren-Tillotson, Inc._2020-10-21_0001581793-20-000005.csv', 'Filer': 'Hefren-Tillotson, Inc.'}, {'File Name': 'Tillar-Wenstrup Advisors, LLC_2020-10-21_0001585045-20-000007.csv', 'Filer': 'Tillar-Wenstrup Advisors, LLC'}, {'File Name': 'Winslow, Evans & Crocker, Inc._2020-10-21_0001597409-20-000004.csv', 'Filer': 'Winslow, Evans & Crocker, Inc.'}, {'File Name': 'CWH Capital Management, Inc._2020-10-21_0001062993-20-005088.csv', 'Filer': 'CWH Capital Management, Inc.'}, {'File Name': 'Gulf International Bank (UK) Ltd_2020-10-21_0001598697-20-000009.csv', 'Filer': 'Gulf International Bank (UK) Ltd'}, {'File Name': 'Crossvault Capital Management LLC_2020-10-21_0001599468-20-000006.csv', 'Filer': 'Crossvault Capital Management LLC'}, {'File Name': 'Gemmer Asset Management LLC_2020-10-21_0001607825-20-000005.csv', 'Filer': 'Gemmer Asset Management LLC'}, {'File Name': 'Sharkey, Howes & Javer_2020-10-21_0001642246-20-000005.csv', 'Filer': 'Sharkey, Howes & Javer'}, {'File Name': 'Canal Capital Management, LLC_2020-10-21_0001420506-20-001077.csv', 'Filer': 'Canal Capital Management, LLC'}, {'File Name': 'Transform Wealth, LLC_2020-10-21_0001085146-20-002589.csv', 'Filer': 'Transform Wealth, LLC'}, {'File Name': 'Patriot Financial Group Insurance Agency, LLC_2020-10-21_0001694883-20-000004.csv', 'Filer': 'Patriot Financial Group Insurance Agency, LLC'}, {'File Name': 'Standard Life Aberdeen plc_2020-10-21_0001085146-20-002594.csv', 'Filer': 'Standard Life Aberdeen plc'}, {'File Name': 'Demars Financial Group, LLC_2020-10-21_0001723115-20-000008.csv', 'Filer': 'Demars Financial Group, LLC'}, {'File Name': 'Fulcrum Capital LLC_2020-10-21_0001724090-20-000005.csv', 'Filer': 'Fulcrum Capital LLC'}, {'File Name': 'Gradient Capital Advisors, LLC_2020-10-21_0001727917-20-000008.csv', 'Filer': 'Gradient Capital Advisors, LLC'}, {'File Name': 'G&S Capital LLC_2020-10-21_0001731448-20-000004.csv', 'Filer': 'G&S Capital LLC'}, {'File Name': 'AltraVue Capital, LLC_2020-10-21_0001740837-20-000004.csv', 'Filer': 'AltraVue Capital, LLC'}, {'File Name': 'Strategic Wealth Management Group, LLC_2020-10-21_0001750403-20-000004.csv', 'Filer': 'Strategic Wealth Management Group, LLC'}, {'File Name': 'Selective Wealth Management, Inc._2020-10-21_0001755670-20-000004.csv', 'Filer': 'Selective Wealth Management, Inc.'}, {'File Name': 'Crumly & Associates Inc._2020-10-21_0001759578-20-000005.csv', 'Filer': 'Crumly & Associates Inc.'}, {'File Name': 'Hamilton Wealth, LLC_2020-10-21_0001085146-20-002591.csv', 'Filer': 'Hamilton Wealth, LLC'}, {'File Name': 'SYQUANT CAPITAL SAS_2020-10-21_0001766392-20-000005.csv', 'Filer': 'SYQUANT CAPITAL SAS'}, {'File Name': 'Emerson Wealth Management, LLC_2020-10-21_0001766671-20-000004.csv', 'Filer': 'Emerson Wealth Management, LLC'}, {'File Name': 'Hoover Financial Advisors, Inc._2020-10-21_0001398344-20-020382.csv', 'Filer': 'Hoover Financial Advisors, Inc.'}, {'File Name': 'Hillcrest Wealth Advisors - NY, LLC_2020-10-21_0001214659-20-008771.csv', 'Filer': 'Hillcrest Wealth Advisors - NY, LLC'}, {'File Name': 'GREAT VALLEY ADVISOR GROUP, INC._2020-10-21_0001085146-20-002595.csv', 'Filer': 'GREAT VALLEY ADVISOR GROUP, INC.'}, {'File Name': 'PRIVATE CAPITAL MANAGEMENT LLC_2020-10-21_0001754960-20-000071.csv', 'Filer': 'PRIVATE CAPITAL MANAGEMENT LLC'}, {'File Name': 'HILLTOP WEALTH ADVISORS, LLC_2020-10-21_0001786241-20-000008.csv', 'Filer': 'HILLTOP WEALTH ADVISORS, LLC'}, {'File Name': 'Cedar Mountain Advisors, LLC_2020-10-21_0001798986-20-000004.csv', 'Filer': 'Cedar Mountain Advisors, LLC'}, {'File Name': 'ATTICUS WEALTH MANAGEMENT, LLC_2020-10-21_0001398344-20-020413.csv', 'Filer': 'ATTICUS WEALTH MANAGEMENT, LLC'}, {'File Name': 'S.A. Mason LLC_2020-10-21_0001800911-20-000009.csv', 'Filer': 'S.A. Mason LLC'}, {'File Name': 'SPRENG CAPITAL MANAGEMENT, INC._2020-10-21_0001085146-20-002597.csv', 'Filer': 'SPRENG CAPITAL MANAGEMENT, INC.'}, {'File Name': 'LifeSteps Financial, Inc._2020-10-21_0001801373-20-000010.csv', 'Filer': 'LifeSteps Financial, Inc.'}, {'File Name': 'PBMares Wealth Management LLC_2020-10-21_0001801682-20-000004.csv', 'Filer': 'PBMares Wealth Management LLC'}, {'File Name': 'Cardinal Strategic Wealth Guidance_2020-10-21_0001801989-20-000005.csv', 'Filer': 'Cardinal Strategic Wealth Guidance'}, {'File Name': 'Veracity Capital LLC_2020-10-21_0001811005-20-000004.csv', 'Filer': 'Veracity Capital LLC'}, {'File Name': 'INTERNATIONAL ASSETS INVESTMENT MANAGEMENT, LLC_2020-10-21_0001420506-20-001073.csv', 'Filer': 'INTERNATIONAL ASSETS INVESTMENT MANAGEMENT, LLC'}, {'File Name': 'Sunflower Bank, N.A._2020-10-21_0001818759-20-000002.csv', 'Filer': 'Sunflower Bank, N.A.'}, {'File Name': 'Tennessee Valley Asset Management Partners_2020-10-21_0001214659-20-008761.csv', 'Filer': 'Tennessee Valley Asset Management Partners'}, {'File Name': 'XXEC, Inc._2020-10-21_0001828822-20-000004.csv', 'Filer': 'XXEC, Inc.'}, {'File Name': 'REGENTS OF THE UNIVERSITY OF CALIFORNIA_2020-10-21_0001567619-20-018039.csv', 'Filer': 'REGENTS OF THE UNIVERSITY OF CALIFORNIA'}, {'File Name': 'AUGUSTINE ASSET MANAGEMENT INC_2020-10-21_0000778963-20-000006.csv', 'Filer': 'AUGUSTINE ASSET MANAGEMENT INC'}, {'File Name': 'CONNING INC._2020-10-21_0001085146-20-002592.csv', 'Filer': 'CONNING INC.'}, {'File Name': 'CAMBIAR INVESTORS LLC_2020-10-21_0001172661-20-002023.csv', 'Filer': 'CAMBIAR INVESTORS LLC'}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "723760ac658c48fba003d3a2d56b86d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drive/Analytics/13fdata/finaldata/EXANE DERIVATIVES_2020-10-08_0001623883-20-000010.csv'\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "(42, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed SWARTHMORE GROUP INC_2020-10-21_0001062993-20-005079.csv\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "(147, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed CenturyLink Investment Management Co_2020-10-21_0001054522-20-000009.csv\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "(244, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Ledyard National Bank_2020-10-21_0001310658-20-000004.csv\n",
            "(101, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Canal Insurance CO_2020-10-21_0001313473-20-000009.csv\n",
            "Completed Intial File\n",
            "(65, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Regis Management CO LLC_2020-10-21_0001352776-20-000012.csv\n",
            "(532, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed ALPHA WINDWARD LLC_2020-10-21_0001353219-20-000004.csv\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "(196, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Paragon Capital Management LLC_2020-10-21_0001388437-20-000006.csv\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "(226, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed WealthTrust Axiom LLC_2020-10-21_0001085146-20-002593.csv\n",
            "(23, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Focused Investors LLC_2020-10-21_0001426398-20-000011.csv\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "(65, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Consolidated Investment Group LLC_2020-10-21_0001104659-20-116668.csv\n",
            "(16, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Spectrum Financial Alliance Ltd LLC_2020-10-21_0001566531-20-000004.csv\n",
            "(745, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Edge Wealth Management LLC_2020-10-21_0001567163-20-000004.csv\n",
            "(130, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Bank OZK_2020-10-21_0000950123-20-010347.csv\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "(760, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Gulf International Bank (UK) Ltd_2020-10-21_0001598697-20-000009.csv\n",
            "(78, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Crossvault Capital Management LLC_2020-10-21_0001599468-20-000006.csv\n",
            "(1420, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Gemmer Asset Management LLC_2020-10-21_0001607825-20-000005.csv\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "(69, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Completed Fulcrum Capital LLC_2020-10-21_0001724090-20-000005.csv\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "Completed Intial File\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZYFwpsIwZVh"
      },
      "source": [
        "def loadFilerData(filer):\n",
        "  filer_data = []\n",
        "  db = get_mongo_client()\n",
        "  meta_df = pd.read_csv('/content/drive/My Drive/Analytics/13fdata/download_status.csv')\n",
        "  #files = list(meta_df[meta_df[\"Filer\"]== filer]['File Name'].unique())\n",
        "  df = meta_df[meta_df[\"Filer\"]==filer]\n",
        "  filer_data_list = df.to_dict('records')\n",
        "  print(filer_data_list)\n",
        "  #db.os13f.delete_many({\"filer\" : filer})\n",
        "  for fd in filer_data_list:\n",
        "    fileID = str(uuid.uuid4())\n",
        "    fileName = fd[\"File Name\"]\n",
        "    filer = fd[\"Filer\"]\n",
        "    quarter = fd[\"Source Quarter\"]\n",
        "    an = fd[\"Accession Number\"]\n",
        "    rank = fd[\"Qrank\"]\n",
        "    df_mg = pd.read_csv('/content/drive/My Drive/Analytics/13fdata/finaldata/'+ fileName)\n",
        "    filer_data.append(df_mg)\n",
        "    filer_data_dict = {\n",
        "                        'fileID': fileID,\n",
        "                        'filer': filer,\n",
        "                        'fileName': fileName,\n",
        "                        'quarter': quarter, \n",
        "                        'acc number': an,\n",
        "                        'rank': rank,\n",
        "                        'filings': df_mg.to_dict('records')}\n",
        "    #db.os13f.insert_one(filer_data_dict)\n",
        "    \n",
        "  filer_data_file = pd.concat(filer_data)\n",
        "  #filer_data_file.to_csv('/content/drive/My Drive/Analytics/13fdata/marts/'+filer+'_final.csv', index=False)\n",
        "  \n",
        "  # put this in gsheet- root folder only\n",
        "\n",
        "  title = '13f-Single-Filer-Analysis'\n",
        "  gc.create(title)  # if not exist\n",
        "  sheet = gc.open(title).sheet1\n",
        "  set_with_dataframe(sheet, filer_data_file, include_index=False, include_column_header=True, resize=False)\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk77ay_7Fg1v"
      },
      "source": [
        "def metadbLoad(md):\n",
        "  db.os13fmeta.insert_one(md)\n",
        "\n",
        "def loadMeta():\n",
        "  #db = get_mongo_client()\n",
        "  meta_df = pd.read_csv('/content/drive/My Drive/Analytics/13fdata/download_status.csv')\n",
        "  meta_df_list = meta_df.to_dict('records') \n",
        "  Parallel(n_jobs=32, backend='multiprocessing')(delayed(metadbLoad)(md) for md in tqdm(meta_df_list))\n",
        "\n",
        "def cusipdbLoad(cusip):\n",
        "  db.os13fcusip.insert_one(cusip)\n",
        "def loadCUSIP():\n",
        "  #db = get_mongo_client()\n",
        "  meta_df = pd.read_csv('/content/drive/My Drive/Analytics/13fdata/CUSIP_LKP.csv', usecols=[\"SYMBOL\", \"CUSIP\"])\n",
        "  meta_df_list = meta_df.to_dict('records')\n",
        "  Parallel(n_jobs=32, backend='multiprocessing')(delayed(cusipdbLoad)(cusip) for cusip in tqdm(meta_df_list))\n",
        "\n",
        "\n",
        "# Accession number check\n",
        "\n",
        "def accession_number_check_mdb(an):\n",
        "  db = get_mongo_client()\n",
        "  acc = db.os13fmeta.find({\"Accession Number\": an})\n",
        "  records = list(acc)\n",
        "  if len(records) == 1:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "# insert cusip records\n",
        "def cusip_mdb(cusip, symbol, sector):\n",
        "  db = get_mongo_client()\n",
        "  cusip_record = {\n",
        "        \"SYMBOL\": symbol,\n",
        "        \"CUSIP\": str(cusip),\n",
        "        \"SECTOR\": sector\n",
        "    }\n",
        "  db.os13fcusip.insert_one(cusip_record)\n",
        "\n",
        "# get cusip records\n",
        "\n",
        "def getcusip_mdb():\n",
        "  db = get_mongo_client()\n",
        "  cusip_data = db.os13fcusip.find({})\n",
        "  cusip_data = list(cusip_data)\n",
        "  return cusip_data\n",
        "\n",
        "# ignoredFilers\n",
        "\n",
        "def ignoredFilers_mdb():\n",
        "  meta_df = pd.read_csv('/content/drive/My Drive/Analytics/13fdata/download_status.csv')\n",
        "  filers = list(meta_df[meta_df[\"Process Status\"].isin([\"DQ Check\", \"Error in QoQ\", \"Empty File\"])][\"Filer\"].unique())\n",
        "  meta_df.loc[meta_df[\"Filer\"].isin(filers),\"Process Status\"] = \"Not Included\" # Updates bad filers\n",
        "  print(\"Total Filers Ignored: \", len(filers))\n",
        "  meta_df.to_csv('/content/drive/My Drive/Analytics/13fdata/download_status.csv', index=False)\n",
        "\n",
        "\n",
        "# get file data\n",
        "def fileNameExtract(status, quarter):\n",
        "  db = get_mongo_client()\n",
        "  files = []\n",
        "  file_data = db.os13fmeta.find({\"$and\": [{\"Process Status\": status},{\"Source Quarter\": quarter}]})\n",
        "  #file_data = db.os13fmeta.find({\"Process Status\": \"Downloaded\"})\n",
        "  file_data = list(file_data)\n",
        "  for fd in file_data:\n",
        "    files.append({\"File Name\": fd[\"File Name\"], \n",
        "                  \"Filer\": fd[\"Filer\"]})\n",
        "  return files\n",
        "\n",
        "# file status\n",
        "\n",
        "def updateFileStatus(fileName, Status):\n",
        "  db = get_mongo_client()\n",
        "  records = db.os13fmeta.update_one({\n",
        "      \"File Name\": fileName\n",
        "  },  {\n",
        "      \"$set\": {\n",
        "          \"Process Status\": Status\n",
        "      }\n",
        "  })"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB5_8X1pxH1m"
      },
      "source": [
        "def cusipDownload():\n",
        "  import requests\n",
        "  from time import sleep\n",
        "  to_be_found = []\n",
        "  # get data from mongo\n",
        "  db = get_mongo_client()\n",
        "  cusip_data = db.os13fcusip.find({})\n",
        "  cusip_data = list(cusip_data)\n",
        "  for cd in cusip_data:\n",
        "    if len(cd) == 3 and cd[\"SYMBOL\"] != \"Not Found\":\n",
        "      to_be_found.append(cd)\n",
        "  for cd in tqdm(to_be_found):\n",
        "    cusip = cd[\"CUSIP\"]\n",
        "    r = requests.get('https://finnhub.io/api/v1/stock/profile2?cusip='+cusip+'&token=bu728rn48v6rghl7pasg')\n",
        "    if r.status_code == 429:\n",
        "      sleep(1)\n",
        "    else: \n",
        "      records = dict(r.json())\n",
        "      if records:  \n",
        "        sector = records[\"finnhubIndustry\"]\n",
        "      else: \n",
        "        sector = \"Unknown\"\n",
        "      \n",
        "      db.os13fcusip.update_one({\n",
        "        \"CUSIP\": cusip\n",
        "          },  {\n",
        "              \"$set\": {\n",
        "                  \"SECTOR\": sector\n",
        "              }\n",
        "          })\n",
        "      sleep(0.5)\n",
        "  apikey = \"bu728rn48v6rghl7pasg\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXQBe34BC-Sk",
        "outputId": "caac85b1-c56f-4e25-8860-f24181791eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "222633e10ddc4e6fa0a4b8c43d8d54e4",
            "53e1d3908b2c4428bdef328aeafe9888",
            "832b881ad5d3449e8579448f22f70566",
            "e48dc694c3a2458abb2b9d7739228362",
            "f5426d7f81f5442e826b87034ec4f5f8",
            "468c6f25445e49b28f0e2fc31f44a2a7",
            "4ea0319fc075470cb33e7e5bde490806",
            "8d674cbc01424bd0ae50eac1b675080f"
          ]
        }
      },
      "source": [
        "cusipDownload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "222633e10ddc4e6fa0a4b8c43d8d54e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1624.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz54BV9mSu6Y"
      },
      "source": [
        "to_be_found = []\n",
        "db = get_mongo_client()\n",
        "cusip_data = db.os13fcusip.find({})\n",
        "cusip_data = list(cusip_data)\n",
        "for cd in cusip_data:\n",
        "  if len(cd) == 3:\n",
        "    if cd[\"SYMBOL\"] != \"Not Found\":\n",
        "      to_be_found.append(cd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2hNtF5AoeSC",
        "outputId": "66fdef63-b2fa-4125-ca56-6231a5a35f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(to_be_found)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP--hWHzLkXG"
      },
      "source": [
        "# get meta_df from mongo or csv\n",
        "xx = []\n",
        "for f in list(meta_df['Filer'].unique()):\n",
        "  temp_df = meta_df[meta_df['Filer'] == f][['File Name', 'Qrank']]\n",
        "  x = temp_df[(temp_df['Qrank'] <= temp_df['Qrank'].max()) & (temp_df['Qrank'] >=temp_df['Qrank'].max()-18)]['File Name'].tolist() # Defines number of files to be included\n",
        "  xx.append(x)\n",
        "xy = [item for sublist in xx for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59GrJKMXZkhq"
      },
      "source": [
        "\n",
        "meta_df.to_csv('/content/drive/My Drive/Analytics/13fdata/download_status.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}